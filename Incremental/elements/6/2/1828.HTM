<HEAD></HEAD>
<BODY>
<H1 style="BOX-SIZING: border-box; MARGIN-BOTTOM: 24px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; MARGIN-TOP: 0.75em; TEXT-TRANSFORM: none; COLOR: ; FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial"><FONT class=extract><SPAN class=section-number style="BOX-SIZING: border-box">4.<SPAN>&nbsp;</SPAN></SPAN>Hardware Implementation</FONT><A title="Permalink to this headline" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-implementation"><FONT class=extract>&#61633;</FONT></A></H1>
<P style="BOX-SIZING: border-box; FONT-SIZE: 16px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(26,26,26); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; MARGIN: 15px 5px 15px 0px; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial"><FONT class=extract>The NVIDIA GPU architecture is built around a scalable array of multithreaded<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">Streaming Multiprocessors</EM><SPAN>&nbsp;</SPAN>(<EM style="BOX-SIZING: border-box">SMs</EM>). When a CUDA program on the host CPU invokes a kernel grid, the blocks of the grid are enumerated and distributed to multiprocessors with available execution capacity. The threads of a thread block execute concurrently on one multiprocessor, and multiple thread blocks can execute concurrently on one multiprocessor. As thread blocks terminate, new blocks are launched on the vacated multiprocessors.</FONT></P>
<P style="BOX-SIZING: border-box; FONT-SIZE: 16px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(26,26,26); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; MARGIN: 15px 5px 15px 0px; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial"><FONT class=extract>A multiprocessor is designed to execute hundreds of threads concurrently. To manage such a large number of threads, it employs a unique architecture called<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">SIMT</EM><SPAN>&nbsp;</SPAN>(<EM style="BOX-SIZING: border-box">Single-Instruction, Multiple-Thread</EM>) that is described in<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture"><FONT class=extract color=#0066cc size=3 face=Arial>SIMT Architecture</FONT></A><FONT class=extract>. The instructions are pipelined, leveraging instruction-level parallelism within a single thread, as well as extensive thread-level parallelism through simultaneous hardware multithreading as detailed in<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-multithreading"><FONT class=extract color=#0066cc size=3 face=Arial>Hardware Multithreading</FONT></A><FONT class=extract>. Unlike CPU cores, they are issued in order and there is no branch prediction or speculative execution.</FONT></P>
<P style="BOX-SIZING: border-box; FONT-SIZE: 16px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(26,26,26); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; MARGIN: 15px 5px 15px 0px; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial"><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture"><FONT class=extract color=#0066cc size=3 face=Arial>SIMT Architecture</FONT></A><FONT class=extract><SPAN>&nbsp;</SPAN>and<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-multithreading"><FONT class=extract color=#0066cc size=3 face=Arial>Hardware Multithreading</FONT></A><FONT class=extract><SPAN>&nbsp;</SPAN>describe the architecture features of the streaming multiprocessor that are common to all devices.<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-5-x"><FONT class=extract color=#0066cc size=3 face=Arial>Compute Capability 5.x</FONT></A><FONT class=extract>,<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-6-x"><FONT class=extract color=#0066cc size=3 face=Arial>Compute Capability 6.x</FONT></A><FONT class=extract>, and<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x"><FONT class=extract color=#0066cc size=3 face=Arial>Compute Capability 7.x</FONT></A><FONT class=extract><SPAN>&nbsp;</SPAN>provide the specifics for devices of compute capabilities 5.x, 6.x, and 7.x respectively.</FONT></P>
<P style="BOX-SIZING: border-box; FONT-SIZE: 16px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(26,26,26); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; MARGIN: 15px 5px 15px 0px; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial"><FONT class=extract>The NVIDIA GPU architecture uses a little-endian representation.</FONT></P><SECTION id=simt-architecture style="BOX-SIZING: border-box; FONT-SIZE: 16px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(26,26,26); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; DISPLAY: block; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial">
<H2 style="BOX-SIZING: border-box; MARGIN-BOTTOM: 24px; FONT-FAMILY: var(--nv-font-face); MARGIN-TOP: 1.25em; COLOR: ; FONT-STYLE: normal"><FONT class=extract><SPAN class=section-number style="BOX-SIZING: border-box">4.1.<SPAN>&nbsp;</SPAN></SPAN>SIMT Architecture</FONT><A title="Permalink to this headline" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture"><FONT class=extract>&#61633;</FONT></A></H2>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>The multiprocessor creates, manages, schedules, and executes threads in groups of 32 parallel threads called<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">warps</EM>. Individual threads composing a warp start together at the same program address, but they have their own instruction address counter and register state and are therefore free to branch and execute independently. The term<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">warp</EM><SPAN>&nbsp;</SPAN>originates from weaving, the first parallel thread technology. A<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">half-warp</EM><SPAN>&nbsp;</SPAN>is either the first or second half of a warp. A<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">quarter-warp</EM><SPAN>&nbsp;</SPAN>is either the first, second, third, or fourth quarter of a warp.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>When a multiprocessor is given one or more thread blocks to execute, it partitions them into warps and each warp gets scheduled by a<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">warp scheduler</EM><SPAN>&nbsp;</SPAN>for execution. The way a block is partitioned into warps is always the same; each warp contains threads of consecutive, increasing thread IDs with the first warp containing thread 0.<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy"><FONT class=extract color=#0066cc size=3>Thread Hierarchy</FONT></A><FONT class=extract><SPAN>&nbsp;</SPAN>describes how thread IDs relate to thread indices in the block.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>A warp executes one common instruction at a time, so full efficiency is realized when all 32 threads of a warp agree on their execution path. If threads of a warp diverge via a data-dependent conditional branch, the warp executes each branch path taken, disabling threads that are not on that path. Branch divergence occurs only within a warp; different warps execute independently regardless of whether they are executing common or disjoint code paths.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>The SIMT architecture is akin to SIMD (Single Instruction, Multiple Data) vector organizations in that a single instruction controls multiple processing elements. A key difference is that SIMD vector organizations expose the SIMD width to the software, whereas SIMT instructions specify the execution and branching behavior of a single thread. In contrast with SIMD vector machines, SIMT enables programmers to write thread-level parallel code for independent, scalar threads, as well as data-parallel code for coordinated threads. For the purposes of correctness, the programmer can essentially ignore the SIMT behavior; however, substantial performance improvements can be realized by taking care that the code seldom requires threads in a warp to diverge. In practice, this is analogous to the role of cache lines in traditional code: Cache line size can be safely ignored when designing for correctness but must be considered in the code structure when designing for peak performance. Vector architectures, on the other hand, require the software to coalesce loads into vectors and manage divergence manually.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>Prior to NVIDIA Volta, warps used a single program counter shared amongst all 32 threads in the warp together with an active mask specifying the active threads of the warp. As a result, threads from the same warp in divergent regions or different states of execution cannot signal each other or exchange data, and algorithms requiring fine-grained sharing of data guarded by locks or mutexes can easily lead to deadlock, depending on which warp the contending threads come from.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>Starting with the NVIDIA Volta architecture,<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">Independent Thread Scheduling</EM><SPAN>&nbsp;</SPAN>allows full concurrency between threads, regardless of warp. With Independent Thread Scheduling, the GPU maintains execution state per thread, including a program counter and call stack, and can yield execution at a per-thread granularity, either to make better use of execution resources or to allow one thread to wait for data to be produced by another. A schedule optimizer determines how to group active threads from the same warp together into SIMT units. This retains the high throughput of SIMT execution as in prior NVIDIA GPUs, but with much more flexibility: threads can now diverge and reconverge at sub-warp granularity.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>Independent Thread Scheduling can lead to a rather different set of threads participating in the executed code than intended if the developer made assumptions about warp-synchronicity</FONT><A id=id21 class="footnote-reference brackets" style="BOX-SIZING: border-box; FONT-SIZE: 14px; CURSOR: pointer; TEXT-DECORATION: none; VERTICAL-ALIGN: baseline; POSITION: relative; COLOR: ; LINE-HEIGHT: 0; TOP: -0.4em" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#fn2"><FONT class=extract>2</FONT></A><FONT class=extract><SPAN>&nbsp;</SPAN>of previous hardware architectures. In particular, any warp-synchronous code (such as synchronization-free, intra-warp reductions) should be revisited to ensure compatibility with NVIDIA Volta and beyond. See<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x"><FONT class=extract color=#0066cc size=3>Compute Capability 7.x</FONT></A><FONT class=extract><SPAN>&nbsp;</SPAN>for further details.</FONT></P>
<DIV id=simt-architecture-notes class="admonition note" style="BOX-SIZING: border-box; MARGIN-BOTTOM: 24px; BACKGROUND: rgb(231,250,223); PADDING-BOTTOM: 12px; PADDING-TOP: 12px; PADDING-LEFT: 12px; CLEAR: both; LINE-HEIGHT: 24px; PADDING-RIGHT: 12px; -webkit-font-smoothing: antialiased">
<P class=admonition-title style="BOX-SIZING: border-box; FONT-FAMILY: inherit; FONT-VARIANT: normal; BACKGROUND: none transparent scroll repeat 0% 0%; FONT-WEIGHT: 700; COLOR: rgb(255,255,255); PADDING-BOTTOM: 6px; FONT-STYLE: normal; PADDING-TOP: 6px; PADDING-LEFT: 12px; MARGIN: -12px -12px 12px; DISPLAY: block; LINE-HEIGHT: 1; PADDING-RIGHT: 12px; text-rendering: auto; -webkit-font-smoothing: antialiased; font-size-adjust: none; font-kerning: auto; font-optical-sizing: auto; font-feature-settings: normal; font-variation-settings: normal; font-stretch: normal"><FONT class=extract>Note</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>The threads of a warp that are participating in the current instruction are called the<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">active</EM><SPAN>&nbsp;</SPAN>threads, whereas threads not on the current instruction are<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">inactive</EM><SPAN>&nbsp;</SPAN>(disabled). Threads can be inactive for a variety of reasons including having exited earlier than other threads of their warp, having taken a different branch path than the branch path currently executed by the warp, or being the last threads of a block whose number of threads is not a multiple of the warp size.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>If a non-atomic instruction executed by a warp writes to the same location in global or shared memory for more than one of the threads of the warp, the number of serialized writes that occur to that location varies depending on the compute capability of the device (see<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-5-x"><FONT class=extract color=#0066cc>Compute Capability 5.x</FONT></A><FONT class=extract>,<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-6-x"><FONT class=extract color=#0066cc>Compute Capability 6.x</FONT></A><FONT class=extract>, and<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x"><FONT class=extract color=#0066cc>Compute Capability 7.x</FONT></A><FONT class=extract>), and which thread performs the final write is undefined.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 0px 0px"><FONT class=extract>If an<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions"><FONT class=extract color=#0066cc>atomic</FONT></A><FONT class=extract><SPAN>&nbsp;</SPAN>instruction executed by a warp reads, modifies, and writes to the same location in global memory for more than one of the threads of the warp, each read/modify/write to that location occurs and they are all serialized, but the order in which they occur is undefined.</FONT></P></DIV></SECTION><SECTION id=hardware-multithreading style="BOX-SIZING: border-box; FONT-SIZE: 16px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(26,26,26); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; DISPLAY: block; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial">
<H2 style="BOX-SIZING: border-box; MARGIN-BOTTOM: 24px; FONT-FAMILY: var(--nv-font-face); MARGIN-TOP: 1.25em; COLOR: ; FONT-STYLE: normal"><FONT class=extract><SPAN class=section-number style="BOX-SIZING: border-box">4.2.<SPAN>&nbsp;</SPAN></SPAN>Hardware Multithreading</FONT><A title="Permalink to this headline" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-multithreading"><FONT class=extract>&#61633;</FONT></A></H2>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>The execution context (program counters, registers, and so on) for each warp processed by a multiprocessor is maintained on-chip during the entire lifetime of the warp. Therefore, switching from one execution context to another has no cost, and at every instruction issue time, a warp scheduler selects a warp that has threads ready to execute its next instruction (the<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture-notes"><FONT class=extract color=#0066cc size=3>active threads</FONT></A><FONT class=extract><SPAN>&nbsp;</SPAN>of the warp) and issues the instruction to those threads.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>In particular, each multiprocessor has a set of 32-bit registers that are partitioned among the warps, and a<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">parallel data cache</EM><SPAN>&nbsp;</SPAN>or<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">shared memory</EM><SPAN>&nbsp;</SPAN>that is partitioned among the thread blocks.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>The number of blocks and warps that can reside and be processed together on the multiprocessor for a given kernel depends on the amount of registers and shared memory used by the kernel and the amount of registers and shared memory available on the multiprocessor. There are also a maximum number of resident blocks and a maximum number of resident warps per multiprocessor. These limits as well the amount of registers and shared memory available on the multiprocessor are a function of the compute capability of the device and are given in<SPAN>&nbsp;</SPAN></FONT><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities"><FONT class=extract color=#0066cc size=3>Compute Capabilities</FONT></A><FONT class=extract>. If there are not enough registers or shared memory available per multiprocessor to process at least one block, the kernel will fail to launch.</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>The total number of warps in a block is as follows:</FONT></P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><SPAN class="math notranslate nohighlight" style="BOX-SIZING: border-box; TEXT-ALIGN: center"><MJX-CONTAINER tabIndex=0 class="MathJax CtxtMenu_Attached_0" style="BOX-SIZING: border-box; FONT-SIZE: 18px; POSITION: relative; LINE-HEIGHT: 0" jax="CHTML" ctxtmenu_counter="0"><MJX-MATH aria-hidden=true class=MJX-TEX style="BOX-SIZING: border-box; FONT-SIZE: 18px; FONT-FAMILY: MJXZERO, MJXTEX; WHITE-SPACE: nowrap; WORD-SPACING: normal; BORDER-COLLAPSE: collapse; FONT-WEIGHT: normal; PADDING-BOTTOM: 1px; DIRECTION: ltr; FONT-STYLE: normal; TEXT-ALIGN: left; PADDING-TOP: 1px; PADDING-LEFT: 0px; DISPLAY: inline-block; LETTER-SPACING: normal; LINE-HEIGHT: 0; PADDING-RIGHT: 0px; TEXT-INDENT: 0px; font-size-adjust: none; overflow-wrap: normal"><MJX-MTEXT class=mjx-n style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class=mjx-c63 style="BOX-SIZING: border-box; DISPLAY: inline-block"></MJX-C><MJX-C class=mjx-c65 style="BOX-SIZING: border-box; DISPLAY: inline-block"></MJX-C><MJX-C class=mjx-c69 style="BOX-SIZING: border-box; DISPLAY: inline-block"></MJX-C><MJX-C class=mjx-c6C style="BOX-SIZING: border-box; DISPLAY: inline-block"></MJX-C></MJX-MTEXT><MJX-MROW style="BOX-SIZING: border-box; TEXT-ALIGN: left; MARGIN-LEFT: 0.16em; DISPLAY: inline-block" space="2"><MJX-MO class=mjx-lop style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class="mjx-c28 TEX-S2" style="BOX-SIZING: border-box; FONT-FAMILY: MJXZERO, MJXTEX-S2; DISPLAY: inline-block"></MJX-C></MJX-MO><MJX-MFRAC style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-FRAC style="BOX-SIZING: border-box; VERTICAL-ALIGN: 0.17em; PADDING-BOTTOM: 0px; PADDING-TOP: 0px; PADDING-LEFT: 0.22em; DISPLAY: inline-block; PADDING-RIGHT: 0.22em"><MJX-NUM style="BOX-SIZING: border-box; TEXT-ALIGN: center; DISPLAY: block"><MJX-NSTRUT style="BOX-SIZING: border-box; HEIGHT: 0.05em; WIDTH: 0px; VERTICAL-ALIGN: -0.05em; DISPLAY: inline-block"></MJX-NSTRUT><MJX-MI class=mjx-i style="BOX-SIZING: border-box; FONT-SIZE: 13px; TEXT-ALIGN: left; DISPLAY: inline-block" size="s"><MJX-C class="mjx-c1D447 TEX-I" style="BOX-SIZING: border-box; FONT-FAMILY: MJXZERO, MJXTEX-I; DISPLAY: inline-block"></MJX-C></MJX-MI></MJX-NUM><MJX-DBOX style="BOX-SIZING: border-box; FONT-SIZE: 0px; DISPLAY: block"><MJX-DTABLE style="BOX-SIZING: border-box; WIDTH: 28px; DISPLAY: inline-table"><MJX-LINE style="BOX-SIZING: border-box; FONT-SIZE: 18px; OVERFLOW: hidden; BORDER-TOP: 0.06em solid; HEIGHT: 0.06em; MIN-HEIGHT: 1px; MARGIN: 0.06em -0.1em; DISPLAY: block"></MJX-LINE><MJX-ROW style="BOX-SIZING: border-box; FONT-SIZE: 18px; DISPLAY: table-row"><MJX-DEN style="BOX-SIZING: border-box; TEXT-ALIGN: center; DISPLAY: block"><MJX-DSTRUT style="BOX-SIZING: border-box; HEIGHT: 0.5em; WIDTH: 0px; DISPLAY: inline-block"></MJX-DSTRUT><MJX-MSUB style="BOX-SIZING: border-box; FONT-SIZE: 13px; TEXT-ALIGN: left; DISPLAY: inline-block" size="s"><MJX-MI class=mjx-i style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class="mjx-c1D44A TEX-I" style="BOX-SIZING: border-box; FONT-FAMILY: MJXZERO, MJXTEX-I; DISPLAY: inline-block"></MJX-C></MJX-MI><MJX-SCRIPT style="BOX-SIZING: border-box; VERTICAL-ALIGN: -0.15em; MARGIN-LEFT: -0.1em"><MJX-TEXATOM style="BOX-SIZING: border-box; FONT-SIZE: 9px; TEXT-ALIGN: left; DISPLAY: inline-block" size="s" texclass="ORD"><MJX-MI class=mjx-i style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class="mjx-c1D460 TEX-I" style="BOX-SIZING: border-box; FONT-FAMILY: MJXZERO, MJXTEX-I; DISPLAY: inline-block"></MJX-C></MJX-MI><MJX-MI class=mjx-i style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class="mjx-c1D456 TEX-I" style="BOX-SIZING: border-box; FONT-FAMILY: MJXZERO, MJXTEX-I; DISPLAY: inline-block"></MJX-C></MJX-MI><MJX-MI class=mjx-i style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class="mjx-c1D467 TEX-I" style="BOX-SIZING: border-box; FONT-FAMILY: MJXZERO, MJXTEX-I; DISPLAY: inline-block"></MJX-C></MJX-MI><MJX-MI class=mjx-i style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class="mjx-c1D452 TEX-I" style="BOX-SIZING: border-box; FONT-FAMILY: MJXZERO, MJXTEX-I; DISPLAY: inline-block"></MJX-C></MJX-MI></MJX-TEXATOM></MJX-SCRIPT></MJX-MSUB></MJX-DEN></MJX-ROW></MJX-DTABLE></MJX-DBOX></MJX-FRAC></MJX-MFRAC><MJX-MO class=mjx-n style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class=mjx-c2C style="BOX-SIZING: border-box; DISPLAY: inline-block"></MJX-C></MJX-MO><MJX-MN class=mjx-n style="BOX-SIZING: border-box; TEXT-ALIGN: left; MARGIN-LEFT: 0.16em; DISPLAY: inline-block" space="2"><MJX-C class=mjx-c31 style="BOX-SIZING: border-box; DISPLAY: inline-block"></MJX-C></MJX-MN><MJX-MO class=mjx-lop style="BOX-SIZING: border-box; TEXT-ALIGN: left; DISPLAY: inline-block"><MJX-C class="mjx-c29 TEX-S2" style="BOX-SIZING: border-box; FONT-FAMILY: MJXZERO, MJXTEX-S2; DISPLAY: inline-block"></MJX-C></MJX-MO></MJX-MROW></MJX-MATH><MJX-ASSISTIVE-MML style="BOX-SIZING: border-box; OVERFLOW: hidden !important; BORDER-TOP: 0px; CLIP: rect(1px 1px 1px 1px); BORDER-RIGHT: 0px; WIDTH: auto !important; BORDER-BOTTOM: 0px; POSITION: absolute !important; PADDING-BOTTOM: 0px !important; PADDING-TOP: 1px !important; PADDING-LEFT: 0px !important; LEFT: 0px; BORDER-LEFT: 0px; DISPLAY: block !important; TOP: 0px; PADDING-RIGHT: 0px !important; user-select: none" unselectable="on" display="inline"><?XML:NAMESPACE PREFIX = "[default] http://www.w3.org/1998/Math/MathML" NS = "http://www.w3.org/1998/Math/MathML" /><math xmlns="http://www.w3.org/1998/Math/MathML"><FONT class=extract><mtext>ceil</mtext><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mi>T</mi><msub><mi>W</mi><mrow data-mjx-texclass="ORD"><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></msub></mfrac><mo>,</mo><mn>1</mn><mo data-mjx-texclass="CLOSE">)</mo></mrow></FONT></math></MJX-ASSISTIVE-MML></MJX-CONTAINER></SPAN></P>
<UL class=simple style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; PADDING-BOTTOM: 0px; PADDING-TOP: 0px; PADDING-LEFT: 0px; MARGIN: 0px 0px 24px; LINE-HEIGHT: 24px; PADDING-RIGHT: 0px">
<LI style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; MARGIN-LEFT: 24px">
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 0px 5px 0px 0px"><FONT class=extract><EM style="BOX-SIZING: border-box">T</EM><SPAN>&nbsp;</SPAN>is the number of threads per block,</FONT></P>
<LI style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; MARGIN-LEFT: 24px">
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 0px 5px 0px 0px"><FONT class=extract><EM style="BOX-SIZING: border-box">Wsize</EM><SPAN>&nbsp;</SPAN>is the warp size, which is equal to 32,</FONT></P>
<LI style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; MARGIN-LEFT: 24px">
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 0px 5px 0px 0px"><FONT class=extract>ceil(x, y) is equal to x rounded up to the nearest multiple of y.</FONT></P></LI></UL>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><FONT class=extract>The total number of registers and total amount of shared memory allocated for a block are documented in the CUDA Occupancy Calculator provided in the CUDA Toolkit.</FONT></P>
<DL class="footnote brackets" style="LIST-STYLE-TYPE: none; BOX-SIZING: border-box; COLOR: grey; PADDING-BOTTOM: 0px; PADDING-TOP: 0px; PADDING-LEFT: 0px; LIST-STYLE-IMAGE: none; MARGIN: 0px 0px 24px; PADDING-RIGHT: 0px; grid-template-columns: max-content auto">
<DT id=fn2 class=label style="BOX-SIZING: border-box; MARGIN-BOTTOM: 0px; MARGIN-TOP: 0px; WORD-BREAK: break-all; FONT-WEIGHT: 400; MARGIN-RIGHT: 0px"><SPAN class=brackets style="BOX-SIZING: border-box"><A class=fn-backref style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#id21"><FONT class=extract>2</FONT></A></SPAN><FONT class=extract> </FONT>
<DD style="BOX-SIZING: border-box; MARGIN: 0px">
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 0px 5px 12px 0px"><FONT class=extract>The term<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">warp-synchronous</EM><SPAN>&nbsp;</SPAN>refers to code that implicitly assumes threads in the same warp are synchronized at every instruction.</FONT></P></DD></DL></SECTION></BODY>