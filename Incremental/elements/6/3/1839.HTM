<b> : </b><SPAN class=section-number style="BOX-SIZING: border-box">5.2.3.<SPAN>&nbsp;</SPAN></SPAN>Multiprocessor Level<A title="Permalink to this headline" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#multiprocessor-level">&#61633;</A></H3>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">At an even lower level, the application should maximize parallel execution between the various functional units within a multiprocessor.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">As described in<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-multithreading"><FONT color=#0066cc size=3>Hardware Multithreading</FONT></A>, a GPU multiprocessor primarily relies on thread-level parallelism to maximize utilization of its functional units. Utilization is therefore directly linked to the number of resident warps. At every instruction issue time, a warp scheduler selects an instruction that is ready to execute. This instruction can be another independent instruction of the same warp, exploiting instruction-level parallelism, or more commonly an instruction of another warp, exploiting thread-level parallelism. If a ready to execute instruction is selected it is issued to the<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture-notes"><FONT color=#0066cc size=3>active</FONT></A><SPAN>&nbsp;</SPAN>threads of the warp. The number of clock cycles it takes for a warp to be ready to execute its next instruction is called the<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">latency</EM>, and full utilization is achieved when all warp schedulers always have some instruction to issue for some warp at every clock cycle during that latency period, or in other words, when latency is completely &#8220;hidden&#8221;. The number of instructions required to hide a latency of L clock cycles depends on the respective throughputs of these instructions (see<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#arithmetic-instructions"><FONT color=#0066cc size=3>Arithmetic Instructions</FONT></A><SPAN>&nbsp;</SPAN>for the throughputs of various arithmetic instructions). If we assume instructions with maximum throughput, it is equal to:</P>
<UL class=simple style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; PADDING-BOTTOM: 0px; PADDING-TOP: 0px; PADDING-LEFT: 0px; MARGIN: 0px 0px 24px; LINE-HEIGHT: 24px; PADDING-RIGHT: 0px">
<LI style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; MARGIN-LEFT: 24px">
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 0px 5px 0px 0px"><EM style="BOX-SIZING: border-box">4L</EM><SPAN>&nbsp;</SPAN>for devices of compute capability 5.x, 6.1, 6.2, 7.x and 8.x since for these devices, a multiprocessor issues one instruction per warp over one clock cycle for four warps at a time, as mentioned in<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities"><FONT color=#0066cc size=3>Compute Capabilities</FONT></A>.</P>
<LI style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; MARGIN-LEFT: 24px">
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 0px 5px 0px 0px"><EM style="BOX-SIZING: border-box">2L</EM><SPAN>&nbsp;</SPAN>for devices of compute capability 6.0 since for these devices, the two instructions issued every cycle are one instruction for two different warps.</P></LI></UL>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The most common reason a warp is not ready to execute its next instruction is that the instruction&#8217;s input operands are not available yet.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">If all input operands are registers, latency is caused by register dependencies, i.e., some of the input operands are written by some previous instruction(s) whose execution has not completed yet. In this case, the latency is equal to the execution time of the previous instruction and the warp schedulers must schedule instructions of other warps during that time. Execution time varies depending on the instruction. On devices of compute capability 7.x, for most arithmetic instructions, it is typically 4 clock cycles. This means that 16 active warps per multiprocessor (4 cycles, 4 warp schedulers) are required to hide arithmetic instruction latencies (assuming that warps execute instructions with maximum throughput, otherwise fewer warps are needed). If the individual warps exhibit instruction-level parallelism, i.e. have multiple independent instructions in their instruction stream, fewer warps are needed because multiple independent instructions from a single warp can be issued back to back.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">If some input operand resides in off-chip memory, the latency is much higher: typically hundreds of clock cycles. The number of warps required to keep the warp schedulers busy during such high latency periods depends on the kernel code and its degree of instruction-level parallelism. In general, more warps are required if the ratio of the number of instructions with no off-chip memory operands (i.e., arithmetic instructions most of the time) to the number of instructions with off-chip memory operands is low (this ratio is commonly called the arithmetic intensity of the program).</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">Another reason a warp is not ready to execute its next instruction is that it is waiting at some memory fence (<A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-fence-functions"><FONT color=#0066cc size=3>Memory Fence Functions</FONT></A>) or synchronization point (<A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#synchronization-functions"><FONT color=#0066cc size=3>Synchronization Functions</FONT></A>). A synchronization point can force the multiprocessor to idle as more and more warps wait for other warps in the same block to complete execution of instructions prior to the synchronization point. Having multiple resident blocks per multiprocessor can help reduce idling in this case, as warps from different blocks do not need to wait for each other at synchronization points.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The number of blocks and warps residing on each multiprocessor for a given kernel call depends on the execution configuration of the call (<A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration"><FONT color=#0066cc size=3>Execution Configuration</FONT></A>), the memory resources of the multiprocessor, and the resource requirements of the kernel as described in<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-multithreading"><FONT color=#0066cc size=3>Hardware Multithreading</FONT></A>. Register and shared memory usage are reported by the compiler when compiling with the<SPAN>&nbsp;</SPAN><CODE class="docutils literal notranslate" style="BOX-SIZING: border-box; FONT-SIZE: 12px; MAX-WIDTH: 100%; BORDER-TOP: rgb(225,228,229) 1px solid; FONT-FAMILY: var(--nv-font-face-mono); BORDER-RIGHT: rgb(225,228,229) 1px solid; BACKGROUND: rgb(255,255,255); WHITE-SPACE: normal; OVERFLOW-X: auto; BORDER-BOTTOM: rgb(225,228,229) 1px solid; COLOR: rgb(231,76,60); PADDING-BOTTOM: 2px; PADDING-TOP: 2px; PADDING-LEFT: 5px; BORDER-LEFT: rgb(225,228,229) 1px solid; PADDING-RIGHT: 5px"><SPAN class=pre style="BOX-SIZING: border-box">--ptxas-options=-v</SPAN></CODE><SPAN>&nbsp;</SPAN>option.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The total amount of shared memory required for a block is equal to the sum of the amount of statically allocated shared memory and the amount of dynamically allocated shared memory.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The number of registers used by a kernel can have a significant impact on the number of resident warps. For example, for devices of compute capability 6.x, if a kernel uses 64 registers and each block has 512 threads and requires very little shared memory, then two blocks (i.e., 32 warps) can reside on the multiprocessor since they require 2x512x64 registers, which exactly matches the number of registers available on the multiprocessor. But as soon as the kernel uses one more register, only one block (i.e., 16 warps) can be resident since two blocks would require 2x512x65 registers, which are more registers than are available on the multiprocessor. Therefore, the compiler attempts to minimize register usage while keeping register spilling (see<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses"><FONT color=#0066cc size=3>Device Memory Accesses</FONT></A>) and the number of instructions to a minimum. Register usage can be controlled using the<SPAN>&nbsp;</SPAN><CODE class="docutils literal notranslate" style="BOX-SIZING: border-box; FONT-SIZE: 12px; MAX-WIDTH: 100%; BORDER-TOP: rgb(225,228,229) 1px solid; FONT-FAMILY: var(--nv-font-face-mono); BORDER-RIGHT: rgb(225,228,229) 1px solid; BACKGROUND: rgb(255,255,255); WHITE-SPACE: normal; OVERFLOW-X: auto; BORDER-BOTTOM: rgb(225,228,229) 1px solid; COLOR: rgb(231,76,60); PADDING-BOTTOM: 2px; PADDING-TOP: 2px; PADDING-LEFT: 5px; BORDER-LEFT: rgb(225,228,229) 1px solid; PADDING-RIGHT: 5px"><SPAN class=pre style="BOX-SIZING: border-box">maxrregcount</SPAN></CODE><SPAN>&nbsp;</SPAN>compiler option, the<SPAN>&nbsp;</SPAN><CODE class="docutils literal notranslate" style="BOX-SIZING: border-box; FONT-SIZE: 12px; MAX-WIDTH: 100%; BORDER-TOP: rgb(225,228,229) 1px solid; FONT-FAMILY: var(--nv-font-face-mono); BORDER-RIGHT: rgb(225,228,229) 1px solid; BACKGROUND: rgb(255,255,255); WHITE-SPACE: normal; OVERFLOW-X: auto; BORDER-BOTTOM: rgb(225,228,229) 1px solid; COLOR: rgb(231,76,60); PADDING-BOTTOM: 2px; PADDING-TOP: 2px; PADDING-LEFT: 5px; BORDER-LEFT: rgb(225,228,229) 1px solid; PADDING-RIGHT: 5px"><SPAN class=pre style="BOX-SIZING: border-box">__launch_bounds__()</SPAN></CODE><SPAN>&nbsp;</SPAN>qualifier as described in<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#launch-bounds"><FONT color=#0066cc size=3>Launch Bounds</FONT></A>, or the<SPAN>&nbsp;</SPAN><CODE class="docutils literal notranslate" style="BOX-SIZING: border-box; FONT-SIZE: 12px; MAX-WIDTH: 100%; BORDER-TOP: rgb(225,228,229) 1px solid; FONT-FAMILY: var(--nv-font-face-mono); BORDER-RIGHT: rgb(225,228,229) 1px solid; BACKGROUND: rgb(255,255,255); WHITE-SPACE: normal; OVERFLOW-X: auto; BORDER-BOTTOM: rgb(225,228,229) 1px solid; COLOR: rgb(231,76,60); PADDING-BOTTOM: 2px; PADDING-TOP: 2px; PADDING-LEFT: 5px; BORDER-LEFT: rgb(225,228,229) 1px solid; PADDING-RIGHT: 5px"><SPAN class=pre style="BOX-SIZING: border-box">__maxnreg__()</SPAN></CODE><SPAN>&nbsp;</SPAN>qualifier as described in<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#maximum-number-of-registers-per-thread"><FONT color=#0066cc size=3>Maximum Number of Registers per Thread</FONT></A>.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The register file is organized as 32-bit registers. So, each variable stored in a register needs at least one 32-bit register, for example, a<SPAN>&nbsp;</SPAN><CODE class="docutils literal notranslate" style="BOX-SIZING: border-box; FONT-SIZE: 12px; MAX-WIDTH: 100%; BORDER-TOP: rgb(225,228,229) 1px solid; FONT-FAMILY: var(--nv-font-face-mono); BORDER-RIGHT: rgb(225,228,229) 1px solid; BACKGROUND: rgb(255,255,255); WHITE-SPACE: normal; OVERFLOW-X: auto; BORDER-BOTTOM: rgb(225,228,229) 1px solid; COLOR: rgb(231,76,60); PADDING-BOTTOM: 2px; PADDING-TOP: 2px; PADDING-LEFT: 5px; BORDER-LEFT: rgb(225,228,229) 1px solid; PADDING-RIGHT: 5px"><SPAN class=pre style="BOX-SIZING: border-box">double</SPAN></CODE><SPAN>&nbsp;</SPAN>variable uses two 32-bit registers.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The effect of execution configuration on performance for a given kernel call generally depends on the kernel code. Experimentation is therefore recommended. Applications can also parametrize execution configurations based on register file size and shared memory size, which depends on the compute capability of the device, as well as on the number of multiprocessors and memory bandwidth of the device, all of which can be queried using the runtime (see reference manual).</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The number of threads per block should be chosen as a multiple of the warp size to avoid wasting computing resources with under-populated warps as much as possible.</P><SECTION id=occupancy-calculator style="BOX-SIZING: border-box; DISPLAY: block">