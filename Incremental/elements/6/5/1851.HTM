<b> : </b><SPAN class=section-number style="BOX-SIZING: border-box">8.1.<SPAN>&nbsp;</SPAN></SPAN>Introduction<A title="Permalink to this headline" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#introduction-cg">&#61633;</A></H2>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">Cooperative Groups is an extension to the CUDA programming model, introduced in CUDA 9, for organizing groups of communicating threads. Cooperative Groups allows developers to express the granularity at which threads are communicating, helping them to express richer, more efficient parallel decompositions.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">Historically, the CUDA programming model has provided a single, simple construct for synchronizing cooperating threads: a barrier across all threads of a thread block, as implemented with the<SPAN>&nbsp;</SPAN><CODE class="docutils literal notranslate" style="BOX-SIZING: border-box; FONT-SIZE: 12px; MAX-WIDTH: 100%; BORDER-TOP: rgb(225,228,229) 1px solid; FONT-FAMILY: var(--nv-font-face-mono); BORDER-RIGHT: rgb(225,228,229) 1px solid; BACKGROUND: rgb(255,255,255); WHITE-SPACE: normal; OVERFLOW-X: auto; BORDER-BOTTOM: rgb(225,228,229) 1px solid; COLOR: rgb(231,76,60); PADDING-BOTTOM: 2px; PADDING-TOP: 2px; PADDING-LEFT: 5px; BORDER-LEFT: rgb(225,228,229) 1px solid; PADDING-RIGHT: 5px"><SPAN class=pre style="BOX-SIZING: border-box">__syncthreads()</SPAN></CODE><SPAN>&nbsp;</SPAN>intrinsic function. However, programmers would like to define and synchronize groups of threads at other granularities to enable greater performance, design flexibility, and software reuse in the form of &#8220;collective&#8221; group-wide function interfaces. In an effort to express broader patterns of parallel interaction, many performance-oriented programmers have resorted to writing their own ad hoc and unsafe primitives for synchronizing threads within a single warp, or across sets of thread blocks running on a single GPU. Whilst the performance improvements achieved have often been valuable, this has resulted in an ever-growing collection of brittle code that is expensive to write, tune, and maintain over time and across GPU generations. Cooperative Groups addresses this by providing a safe and future-proof mechanism to enable performant code.</P></SECTION><SECTION id=what-s-new-in-cooperative-groups style="BOX-SIZING: border-box; FONT-SIZE: 16px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(26,26,26); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; DISPLAY: block; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial">