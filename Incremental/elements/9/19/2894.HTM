<H2><B><FONT class=extract>1. Leader Election Basics</FONT></B></H2>
<H3><B><FONT class=extract>1.1 Definition</FONT></B></H3>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">Sometimes horizontally scaling a system is as simple as spinning up a cluster of nodes and letting each node respond to whatever subset of the incoming requests they receive. At other times, the task at hand requires more precise coordination between the nodes and it&#8217;s helpful to have a </SPAN><B>leader</B><SPAN style="FONT-WEIGHT: 400"> node directing what the </SPAN><B>follower</B><SPAN style="FONT-WEIGHT: 400"> nodes work on.</SPAN></FONT></P>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">A </SPAN><B>leader election algorithm </B><SPAN style="FONT-WEIGHT: 400">describes how a cluster of nodes without a leader can communicate with each other to choose exactly one of themselves to become the leader. The algorithm is executed whenever the cluster starts or when the leader node goes down.&nbsp;</SPAN></FONT></P>
<H3><B><FONT class=extract>1.2 When to use</FONT></B></H3>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>There are three cases to consider when deciding if leader election fits the situation. </FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>The first case is when each node is roughly the same and there isn't a clear candidate for a permanently assigned leader. This means any node can be elected as leader, and there isn&#8217;t a single point of failure required to coordinate the system. </FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>The second case is when the cluster is doing particularly complex work that needs good coordination. Coordination can mean anything from decisions about how the work is to be divided, to assigning work to specific nodes, or to synthesizing the results of work from different nodes.</FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Let&#8217;s consider for example a scientific computation that is trying to determine how a protein folds. Because there are so many possible solutions, this computation can take a long time and will be sped up considerably if it&#8217;s distributed. The cluster will need a leader node to assign each node to work on a different part of the computation, and then add the results together to get the complete folded protein configuration. </FONT></SPAN></P>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">The third case where leader election adds value is when a system executes many distributed writes to data and requires </SPAN><B>strong consistency</B><SPAN style="FONT-WEIGHT: 400">. You can read more about consistency in </SPAN></FONT><A href="https://igotanoffer.com/blogs/tech/databases-system-design-interview"><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>our article on Databases</FONT></SPAN></A><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>, but essentially this means it's very important that no matter what node handles a request the user will always have the most up-to-date version of the data. In this situation a leader creates consistency guarantees by being the source of truth on what the most recent state of the system is (and the leader election algorithm must preserve this properly). </FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Not all applications require strong consistency, but you can imagine how it might be important to a bank to ensure that no matter what server answers a user's online banking request their bank account total will be accurate, and that multiple transactions directed to the same bank account won't conflict with each other.</FONT></SPAN></P>
<H3><B><FONT class=extract>1.3 Drawbacks</FONT></B></H3>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>The main downside to leader election is complexity: a bad implementation can end up with &#8220;split brain&#8221; where two leaders try to control at the same time, or no leader is elected and the cluster can&#8217;t coordinate. As such, leader election should only be used when there is a need for complex coordination or strong consistency, and none of the alternatives fit the situation.</FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>A leader is a single node, so it can become a bottleneck or temporary single point of failure. Additionally, if the leader starts making bad decisions (whatever that means in the context of directing work for the service), the followers will just do what they're assigned, possibly derailing the entire cluster.</FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>The leader / follower model generally makes the best practices of partial deployment and A/B testing harder by requiring the whole cluster to follow the same protocols or be able to respond uniformly to the same leader.</FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Now that we've gone over the benefits and downsides of leader election, and you know when it's appropriate to use, let's jump into the algorithm approaches for implementing it!</FONT></SPAN></P>
<H2><A name=algorithms></A><B><FONT class=extract>2. Leader Election Algorithms</FONT></B></H2>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">A </SPAN><B>leader election algorithm</B><SPAN style="FONT-WEIGHT: 400"> guides a cluster to collectively agree on one node to act as leader with as few back and forth communications as possible.</SPAN></FONT></P>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">Generally, the algorithm works by assigning one of three states to each node: Leader, Follower, or Candidate. Additionally the leader will be required to regularly pass a </SPAN><B>"healthcheck"</B><SPAN style="FONT-WEIGHT: 400"> or </SPAN><B>&#8220;heartbeat&#8221;</B><SPAN style="FONT-WEIGHT: 400"> so follower nodes can tell if the leader has become unavailable or failed and a new one needs to be elected.</SPAN></FONT></P>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">The kind of leader election algorithm you want depends on whether the cluster is synchronous or asynchronous. In a </SPAN><B>synchronous </B><SPAN style="FONT-WEIGHT: 400">cluster nodes are synchronized to the same clock and send messages in predictable amounts of time and ordering. In an </SPAN><B>asynchronous </B><SPAN style="FONT-WEIGHT: 400">cluster </SPAN><SPAN style="FONT-WEIGHT: 400">messages are not reliably delivered within a certain amount of time or in any order.&nbsp;</SPAN></FONT></P>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">In an asynchronous cluster any number of nodes can lag indefinitely so the leader election process can't guarantee both </SPAN><B>safety</B><SPAN style="FONT-WEIGHT: 400"> - that no more than one leader will be elected - and </SPAN><B>liveness</B><SPAN style="FONT-WEIGHT: 400"> - that every node will finish the election. In practice, implementations choose to guarantee safety because it has more critical implications for the service.&nbsp;</SPAN></FONT></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Synchronous algorithms can guarantee both safety and liveness, and are therefore easier to reason about and theoretically preferable. But in practice the big drawback is synchronizing a cluster requires implementing additional constraints on how the cluster operates that aren&#8217;t always feasible or scalable.</FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Now let&#8217;s take a deeper look at the four most popular leader election algorithms.</FONT></SPAN></P>
<H3><B><FONT class=extract>2.1 Bully Algorithm</FONT></B></H3>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">The </SPAN><B>Bully Algorithm</B><SPAN style="FONT-WEIGHT: 400"> is a simple </SPAN><I><SPAN style="FONT-WEIGHT: 400">synchronous</SPAN></I><SPAN style="FONT-WEIGHT: 400"> leader election algorithm. This algorithm requires that each nodes has a unique numeric id, and that nodes know the ids of all other nodes in the cluster.</SPAN></FONT></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>The election process starts when a node starts up or when the current leader fails the healthcheck. There are two cases:</FONT></SPAN></P>
<OL>
<LI style="FONT-WEIGHT: 400"><FONT class=extract><SPAN style="FONT-WEIGHT: 400">if the node has the highest id, it declares itself the winner and sends this message to the rest of the nodes.</SPAN> </FONT>
<LI style="FONT-WEIGHT: 400"><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>if the node has a lower id, it messages all nodes with higher ids and if it doesn't get a response, it assumes all of them have failed or are unavailable, and declares itself the winner.</FONT></SPAN></LI></OL>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>The main downside of the bully algorithm is that if the highest-ranked node goes down frequently, it will re-claim leadership every time it comes back online, causing unnecessary reelections. Synchronization of messages can also be difficult to maintain, especially as the cluster gets larger and physically distributed.&nbsp;</FONT></SPAN></P>
<H3><B><FONT class=extract>2.2 Paxos</FONT></B></H3>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Paxos is a general consensus protocol that can be used for asynchronous leader election. Quite a lot of research has been done about the Paxos family of algorithms, which means it's both robust and there's </FONT></SPAN><A href="https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf"><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>much more to say about it</FONT></SPAN></A><SPAN style="FONT-WEIGHT: 400"><FONT class=extract> than we have space for in this article.</FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>You don&#8217;t need to know all the details of Paxos for designing systems, in fact for leader election generally it&#8217;s best to choose an existing implementation because of the complexity. It&#8217;s unlikely that your system will have a feature constraint that isn&#8217;t already covered by an existing open source library or service. </FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Very briefly, Paxos uses </FONT></SPAN><A href="https://en.wikipedia.org/wiki/State_machine_replication"><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>state machine replication</FONT></SPAN></A><FONT class=extract><SPAN style="FONT-WEIGHT: 400"> to model the distributed system, and then chooses a leader by having some nodes propose a leader, and some nodes accept proposals. When a </SPAN><B>quorum</B><SPAN style="FONT-WEIGHT: 400"> of (enough of) the accepting nodes choose the same proposed leader, that proposed leader becomes the actual leader.</SPAN></FONT></P>
<H3><B><FONT class=extract>2.3 RAFT</FONT></B></H3>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Raft is an alternative to Paxos that is favored because people tend to find it simpler to understand, and therefore easier to implement and use. Raft is an asynchronous algorithm. </FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>In Raft consensus, each node keeps track of the current "election term". When leader election starts each node increments its copy of the term number and listens for messages from other nodes. After a random interval, if the node doesn't hear anything, it will become a candidate leader and ask other nodes for votes. </FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>If the candidate ever reaches a majority of votes, it becomes a leader, and if it ever receives a message from another candidate with a higher term number, it concedes. The algorithm restarts if the election is split or times out without consensus. Restarts don't happen too often because the random timeouts help make it so nodes don't usually conflict.</FONT></SPAN></P>
<H3><B><FONT class=extract>2.4 Apache ZooKeeper (ZAB)</FONT></B></H3>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Apache Zookeeper is a centralized coordination service that is </FONT></SPAN><A href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Index"><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>&#8220;itself distributed and highly reliable.&#8221;</FONT></SPAN></A><SPAN style="FONT-WEIGHT: 400"><FONT class=extract> The ethos behind Apache ZooKeeper is that coordination in distributed systems is difficult, and it&#8217;s better to have a shared open source implementation with all the key elements so that your service doesn&#8217;t have to reimplement everything from scratch. This is especially helpful in large distributed systems.</FONT></SPAN></P>
<P><FONT class=extract><B>ZAB</B><SPAN style="FONT-WEIGHT: 400"> (ZooKeeper Atomic Broadcast) is the protocol used by Apache ZooKeeper to handle leader election, replication order guarantees, and node recovery. It is called this because the leader &#8220;broadcasts&#8221; state changes to followers to make sure writes are consistent and propagated to all nodes. ZAB is an asynchronous algorithm. </SPAN></FONT></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>ZAB is focused on making sure the history of the cluster is accurate through leadership transitions. The leader is chosen such that it has the most up to date history (it has seen the most recent transaction). When enough of the nodes agree that the new leader has the most up to date history, it syncs history with the cluster and finishes the election by recording itself as leader.&nbsp;</FONT></SPAN></P>
<H2><A name=alternatives></A><B><FONT class=extract>3. Alternatives to leader election</FONT></B></H2>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Alternatives to leader election are based on the premise that coordination is possible without a dedicated leader node, thus achieving the primary function of leader election with lower implementation complexity. </FONT></SPAN></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Here&#8217;s a brief overview of three of the most notable alternatives:</FONT></SPAN></P>
<H3><B><FONT class=extract>3.1 Locking</FONT></B></H3>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">A locking model ensures that concurrent operations on a shared resource don't conflict by only allowing changes from one node at a time. With</SPAN><B> optimistic locking </B><SPAN style="FONT-WEIGHT: 400">a node will read a resource and its version id, make changes, and then before updating make sure that the version id is the same. If the id is different this means the resource has been updated since the node first read it. Going forward with the intended changes based on the old id would lose the other changes, so&nbsp; the node needs to try again.</SPAN></FONT></P>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">In </SPAN><B>pessimistic locking</B><SPAN style="FONT-WEIGHT: 400"> a node locks the resource, makes changes, and then unlocks the resource. If another node tries to initiate a change while the resource is locked, it will fail and try again later. Pessimistic locking is more rigorous, but can be hard to implement and bugs can cause </SPAN><B>deadlocks</B><SPAN style="FONT-WEIGHT: 400"> that stop a system from functioning.</SPAN></FONT></P>
<P><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>These locking patterns are named for use cases. Optimistic locking is useful when you can make the "optimistic" assumption that another node won't change the resource out from under the operation. And pessimistic locking is useful when you can make the "pessimistic" assumption that there will be contention for the resource.</FONT></SPAN></P>
<H3><B><FONT class=extract>3.2 Idempotent APIs</FONT></B></H3>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">APIs can have the feature of </SPAN><B>idempotency </B><SPAN style="FONT-WEIGHT: 400">to ensure consistent interactions with a shared resource. An API is idempotent when the same request sent multiple times will not produce any inconsistent results. When reading from a resource, this means the response will always be the same value. When writing, this means the update will only happen once.</SPAN></FONT></P>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">For example, idempotent </SPAN><I><SPAN style="FONT-WEIGHT: 400">writes </SPAN></I><SPAN style="FONT-WEIGHT: 400">can be implemented by requiring request ids so the system can tell if a request is being retried. Idempotency is also supported by other features we've talked about, like locking and database transactions. </SPAN></FONT></P>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">An intuitive example of an idempotent API is bank account transfers: if a user initiates an online bank transfer and their internet goes down halfway through processing, you want to make sure the user can initiate the transfer again and your system will correctly only transfer the amount </SPAN><I><SPAN style="FONT-WEIGHT: 400">once</SPAN></I><SPAN style="FONT-WEIGHT: 400">.</SPAN></FONT></P>
<H3><B><FONT class=extract>3.3 Workflow Engines</FONT></B></H3>
<P><FONT class=extract><SPAN style="FONT-WEIGHT: 400">Another way of coordinating nodes in a system is by using a </SPAN><B>workflow engine </B><SPAN style="FONT-WEIGHT: 400">. A workflow engine is a centralized decision making system that contains a set of "workflows" of what work can be done, the state of data and work in the system, and the resources available to assign work to. Popular solutions are </SPAN></FONT><A href="https://aws.amazon.com/step-functions"><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>AWS Step Functions</FONT></SPAN></A><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>, </FONT></SPAN><A href="https://airflow.apache.org/"><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>Apache Airflow</FONT></SPAN></A><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>, and </FONT></SPAN><A href="https://docs.microsoft.com/en-us/dotnet/framework/windows-workflow-foundation/state-machine-workflows"><SPAN style="FONT-WEIGHT: 400"><FONT class=extract>.NET State Machines</FONT></SPAN></A>