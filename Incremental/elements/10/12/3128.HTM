<HEADER class=entry-header style="FONT-SIZE: 16px; FONT-FAMILY: Lato; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(131,131,131); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; DISPLAY: block; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial">
<H2 class=entry-title style="FONT-SIZE: 28px; FONT-FAMILY: Lora; FONT-WEIGHT: 400; COLOR: rgb(0,0,0); CLEAR: both; MARGIN: 14px 0px; LINE-HEIGHT: 1.4; overflow-wrap: break-word">Sloppy Quorum and Hinted handoff: Quorum in the times of failure</H2></HEADER>
<DIV class=entry-content style="FONT-SIZE: 16px; FONT-FAMILY: Lato; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(131,131,131); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; MARGIN: 0px; LETTER-SPACING: normal; COUNTER-RESET: footnotes 0; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial">
<P style="MARGIN: 0px 0px 1em"></P>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">As part of a blog post in the past, we discussed how<SPAN>&nbsp;</SPAN><A style="TEXT-DECORATION: underline; COLOR: rgb(254,70,58); BACKGROUND-COLOR: transparent" href="https://distributed-computing-musings.com/2022/01/replication-maintaining-a-quorum/">Quorums</A><SPAN>&nbsp;</SPAN>play a huge part in multi-node system. In order to revisit the concept we just need to focus on three attributes that define a quorum.</P>
<UL class="has-black-color has-text-color" style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; COLOR: rgb(47,54,51); PADDING-LEFT: 1.5em; MARGIN: 0px">
<LI>N &#8211; Total number of nodes in our system</LI>
<LI>W &#8211; Minimum number of nodes required for a successful write operation</LI>
<LI>R &#8211; Minimum number of nodes required for a successful read operation</LI></UL>
<P style="MARGIN: 0px 0px 1em"></P>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">For maintaining a successful quorum, we have to ensure that<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>R + W &gt; N</CODE>. Even though this criteria looks achievable in the first look, we will start seeing its limitations once our system in deployed on more than one cluster of nodes or once we start seeing frequent node failures in our system. Quorums are not fault tolerant and we can easily end up in a scenario where the nodes from one cluster are unable to communicate to nodes from another cluster. This will result in failure to reach a quorum and result in failing read and write requests from the client.</P>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">Consider a scenario where we have to assigned<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>N</CODE><SPAN>&nbsp;</SPAN>nodes for a particular key. These<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>N</CODE><SPAN>&nbsp;</SPAN>nodes are spread across two clusters and none of these clusters have more than<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>W - 1</CODE><SPAN>&nbsp;</SPAN>nodes for this key. Whenever we receive a request from the client to update the key, we send it to these<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>N</CODE><SPAN>&nbsp;</SPAN>nodes and if we receive a confirmation from<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>W</CODE><SPAN>&nbsp;</SPAN>of these<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>N</CODE><SPAN>&nbsp;</SPAN>nodes, we consider the update to be successful. Now if we encounter a network failure between these two node clusters then we won&#8217;t be able to reach a quorum for all the upcoming write requests as we are unable to communicate across all<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>N</CODE><SPAN>&nbsp;</SPAN>nodes and gather at least<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>W</CODE><SPAN>&nbsp;</SPAN>votes to get a quorum.</P>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">To handle the above issue we have a modified version of quorum called as<SPAN>&nbsp;</SPAN><STRONG style="FONT-WEIGHT: bold; COLOR: rgb(123,123,123)">Sloppy Quorum</STRONG>. Under sloppy quorum, when we are unable to reach all the<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>N</CODE><SPAN>&nbsp;</SPAN>nodes due to a partition failure, we temporarily store the updates on backup nodes. These backup nodes were not initially responsible for storing updates for the required key but they store the updates only in case of partition failure. The updates are stored along with the metadata which describes the original node that the key was required to be stored on.</P>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">So let us now revisit the above example. We had<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>N</CODE><SPAN>&nbsp;</SPAN>nodes spread across two clusters<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>P1</CODE><SPAN>&nbsp;</SPAN>&amp;<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>P2</CODE>. Now we are unable to reach<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>P2</CODE><SPAN>&nbsp;</SPAN>cluster so in order to save an update for a key, we will go through the following flow:</P>
<UL class="has-black-color has-text-color" style="LIST-STYLE-TYPE: disc; BOX-SIZING: border-box; COLOR: rgb(47,54,51); PADDING-LEFT: 1.5em; MARGIN: 0px">
<LI>Store the update on original nodes for the key on<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>P1</CODE><SPAN>&nbsp;</SPAN>cluster</LI>
<LI>Store update on backup nodes present on<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>P1</CODE><SPAN>&nbsp;</SPAN>cluster. Each backup node maps to the original node on<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>P2</CODE><SPAN>&nbsp;</SPAN>cluster. The update will contain the details about which node the update originally belongs to on<SPAN>&nbsp;</SPAN><CODE style='FONT-FAMILY: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace'>P2</CODE><SPAN>&nbsp;</SPAN>cluster</LI></UL>
<P style="MARGIN: 0px 0px 1em"></P>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">With above flow, we are able to reach a quorum and process the write request for the client. Each backup node will ping the original node on P2 cluster to check if partition failure is resolved. Once the backup node is able to communicate, it will share the update with original node on P2 cluster and remove the update from its own storage. This process of sharing the update post failure resolution is called<STRONG style="FONT-WEIGHT: bold; COLOR: rgb(123,123,123)"><SPAN>&nbsp;</SPAN>hinted handoff</STRONG>.</P>
<P class="has-black-color has-text-color" style="FONT-SIZE: 26px; COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">In simple words&#8230;</P>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">A real-life example of sloppy quorum &amp; hinted handoff will be if a coworker takes a message on your behalf once you are out on a break and shares the message with you once you are back. If you didn&#8217;t had such an understanding coworker with you then you might have missed the message completely. You will have to figure out on your own about what messages you missed and will be scared to leave your desk in future for a break.</P>
<P class="has-black-color has-text-color" style="FONT-SIZE: 26px; COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">Conclusion</P>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">So why not always use the updated variation of sloppy quorum and hinted handoff instead of boring old quorum? While this updated variation is perfect for a write-heavy system. It might not be the best solution if your system requires consistent reads. During network failure, your system will mark a write operation as successful by using sloppy quorum but note that not all the nodes for this updated record are in sync with the most recent update. So even though clusters in your system are unable to communicate amongst each other, a client might be able to send a read request to an outdated cluster and will receive a stale value. Systems that can tolerate eventually consistent results are the best candidates for this methodology. One example of such system is Dynamo which leverages sloppy quorum and hinted handoff to overcome temporary node and partition failure.</P>
<DIV class=wp-block-image style="MARGIN: 2em 0px"><FIGURE class="aligncenter size-large" style="CLEAR: both; MARGIN: 0px auto; DISPLAY: table"><IMG class=wp-image-614 style="BOX-SIZING: border-box; MAX-WIDTH: 100%; BORDER-TOP: 0px; HEIGHT: auto; BORDER-RIGHT: 0px; VERTICAL-ALIGN: middle; MARGIN-TOP: 0px !important; BORDER-BOTTOM: 0px; BORDER-LEFT: 0px" alt="" src="https://distributed-computing-musings.com/wp-content/uploads/2022/05/Screen-Shot-2022-05-22-at-3.03.26-PM-1024x420.png" width=1024 height=420 sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://distributed-computing-musings.com/wp-content/uploads/2022/05/Screen-Shot-2022-05-22-at-3.03.26-PM-1024x420.png 1024w, https://distributed-computing-musings.com/wp-content/uploads/2022/05/Screen-Shot-2022-05-22-at-3.03.26-PM-300x123.png 300w, https://distributed-computing-musings.com/wp-content/uploads/2022/05/Screen-Shot-2022-05-22-at-3.03.26-PM-768x315.png 768w, https://distributed-computing-musings.com/wp-content/uploads/2022/05/Screen-Shot-2022-05-22-at-3.03.26-PM.png 1482w" decoding="async" fetchpriority="high"></FIGURE></DIV>
<P class="has-black-color has-text-color" style="COLOR: rgb(47,54,51); MARGIN: 0px 0px 1em">As an application developer, you will have to make the call about using sloppy quorum over strict quorum based on what are the requirements for your system. If you have strict requirements on showing the most consistent state to end-user then stick to strict quorums and the ask the client to retry in case of node/network failures. But if you are ok with eventually consistent results then you can start exploring the combination of sloppy quorum and hinted handoff to build a highly available system.</P></DIV>