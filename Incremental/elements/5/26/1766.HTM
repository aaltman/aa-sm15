<b> : </b><SPAN class=section-number style="BOX-SIZING: border-box">2.4.<SPAN>&nbsp;</SPAN></SPAN>Heterogeneous Programming<A title="Permalink to this headline" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#heterogeneous-programming">&#61633;</A></H2>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">As illustrated by<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#heterogeneous-programming-heterogeneous-programming"><FONT color=#0066cc size=3>Figure 7</FONT></A>, the CUDA programming model assumes that the CUDA threads execute on a physically separate<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">device</EM><SPAN>&nbsp;</SPAN>that operates as a coprocessor to the<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">host</EM><SPAN>&nbsp;</SPAN>running the C++ program. This is the case, for example, when the kernels execute on a GPU and the rest of the C++ program executes on a CPU.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The CUDA programming model also assumes that both the host and the device maintain their own separate memory spaces in DRAM, referred to as<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">host memory</EM><SPAN>&nbsp;</SPAN>and<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">device memory</EM>, respectively. Therefore, a program manages the global, constant, and texture memory spaces visible to kernels through calls to the CUDA runtime (described in<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-interface"><FONT color=#0066cc size=3>Programming Interface</FONT></A>). This includes device memory allocation and deallocation as well as data transfer between host and device memory.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">Unified Memory provides<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">managed memory</EM><SPAN>&nbsp;</SPAN>to bridge the host and device memory spaces. Managed memory is accessible from all CPUs and GPUs in the system as a single, coherent memory image with a common address space. This capability enables oversubscription of device memory and can greatly simplify the task of porting applications by eliminating the need to explicitly mirror data on host and device. See<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-unified-memory-programming-hd"><FONT color=#0066cc size=3>Unified Memory Programming</FONT></A><SPAN>&nbsp;</SPAN>for an introduction to Unified Memory.</P><FIGURE id=heterogeneous-programming-heterogeneous-programming class=align-center style="BOX-SIZING: border-box; TEXT-ALIGN: center; MARGIN: auto; DISPLAY: block"><IMG style="BOX-SIZING: border-box; MAX-WIDTH: 100%; BORDER-TOP: 0px; HEIGHT: auto; BORDER-RIGHT: 0px; VERTICAL-ALIGN: middle; BORDER-BOTTOM: 0px; BORDER-LEFT: 0px" alt="Heterogeneous Programming" src="https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/heterogeneous-programming.png"><FIGCAPTION style="BOX-SIZING: border-box; DISPLAY: block">
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px"><SPAN class=caption-number style="BOX-SIZING: border-box">Figure 7<SPAN>&nbsp;</SPAN></SPAN><SPAN class=caption-text style="BOX-SIZING: border-box; FONT-STYLE: italic">Heterogeneous Programming</SPAN><A title="Permalink to this image" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#heterogeneous-programming-heterogeneous-programming">&#61633;</A></P>
<DIV class=legend style="BOX-SIZING: border-box">
<DIV class="admonition note" style="BOX-SIZING: border-box; MARGIN-BOTTOM: 24px; BACKGROUND: rgb(231,250,223); PADDING-BOTTOM: 12px; PADDING-TOP: 12px; PADDING-LEFT: 12px; CLEAR: both; LINE-HEIGHT: 24px; PADDING-RIGHT: 12px; -webkit-font-smoothing: antialiased">
<P class=admonition-title style="BOX-SIZING: border-box; FONT-FAMILY: inherit; FONT-VARIANT: normal; BACKGROUND: none transparent scroll repeat 0% 0%; FONT-WEIGHT: 700; COLOR: rgb(255,255,255); PADDING-BOTTOM: 6px; FONT-STYLE: normal; PADDING-TOP: 6px; PADDING-LEFT: 12px; MARGIN: -12px -12px 12px; DISPLAY: block; LINE-HEIGHT: 1; PADDING-RIGHT: 12px; text-rendering: auto; -webkit-font-smoothing: antialiased; font-size-adjust: none; font-kerning: auto; font-optical-sizing: auto; font-feature-settings: normal; font-variation-settings: normal; font-stretch: normal">Note</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 0px 0px">Serial code executes on the host while parallel code executes on the device.</P></DIV></DIV></FIGCAPTION></FIGURE></SECTION><SECTION id=asynchronous-simt-programming-model style="BOX-SIZING: border-box; FONT-SIZE: 16px; FONT-FAMILY: NVIDIA, Arial, Helvetica, sans-serif; WHITE-SPACE: normal; WORD-SPACING: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(26,26,26); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; DISPLAY: block; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(255,255,255); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial">