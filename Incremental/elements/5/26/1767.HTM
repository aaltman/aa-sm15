<b> : </b><SPAN class=section-number style="BOX-SIZING: border-box">2.5.<SPAN>&nbsp;</SPAN></SPAN>Asynchronous SIMT Programming Model<A title="Permalink to this headline" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-simt-programming-model">&#61633;</A></H2>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">In the CUDA programming model a thread is the lowest level of abstraction for doing a computation or a memory operation. Starting with devices based on the NVIDIA Ampere GPU architecture, the CUDA programming model provides acceleration to memory operations via the asynchronous programming model. The asynchronous programming model defines the behavior of asynchronous operations with respect to CUDA threads.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">The asynchronous programming model defines the behavior of<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#aw-barrier"><FONT color=#0066cc size=3>Asynchronous Barrier</FONT></A><SPAN>&nbsp;</SPAN>for synchronization between CUDA threads. The model also explains and defines how<SPAN>&nbsp;</SPAN><A class="reference external" style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: " href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#asynchronous-data-copies"><FONT color=#0066cc size=3>cuda::memcpy_async</FONT></A><SPAN>&nbsp;</SPAN>can be used to move data asynchronously from global memory while computing in the GPU.</P><SECTION id=asynchronous-operations style="BOX-SIZING: border-box; DISPLAY: block">