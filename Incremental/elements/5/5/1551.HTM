Abstract<BR>Recently, Bronson et al. [7] introduced a framework for un- derstanding a class of failures in distributed systems called metastable failures. The examples of metastable failures pre- sented in that work are simplified versions of failures observed at Facebook. In this work, we study the prevalence of such fail- ures in the wild by scouring over publicly available incident reports from many organizations, ranging from hyperscalers to small companies.<BR>Our main findings are threefold. First, metastable failures are universally observed&#8212;we present an in-depth study of 22 metastable failures from 11 different organizations. Second, metastable failures are a recurring pattern in many severe outages&#8212;e.g., at least 4 out of 15 major outages in the last decade at Amazon Web Services were caused by metastable failures. Third, we extend the model by Bronson et al. to better reflect the metastable failures seen in the wild by cate- gorizing two types of triggers and two types of amplification mechanisms, which we confirm through developing multi- ple example applications that reproduce different types of metastable failures in a controlled environment. We believe our work will aid in a deeper understanding of metastable failures and in coming up with solutions to them.<BR>&nbsp;&nbsp;&nbsp; 1 Introduction<BR>Building reliable distributed systems has been the holy grail of distributed computing research. Historically, academic re- searchers studied the reliability of distributed systems under the assumptions of fail-stop [31, 42, 46] and Byzantine [8, 32] failure modes. The proliferation of cloud services led to previously unseen scales and the discovery of new failure modes, such as stragglers [9, 12, 62], fail-slow hardware fail- ures [3, 27, 29], and scalability failures [34, 53]. Most recently, Bronson et al. [7] introduced a new class of failures called metastable failures.<BR>Bronson et al. define the metastable failure state as the state of a permanent overload with an ultra-low goodput (throughput of useful work). In their framework, they also define the stable state as the state when a system experiences a low enough load than it can successfully recover from tem- porary overloads, and the vulnerable state as the state when a system experiences a high load, but it can successfully handle that load in the absence of temporary overloads. A system ex- periences a metastable failure when it is in a vulnerable state and a trigger causes a temporary overload that sets off a sus- taining effect&#8212;a work amplification due to a common-case<BR>*Equal contribution.<BR>optimization&#8212;that tips the system into a metastable failure state. The distinguishing characteristic of a metastable failure is that the sustaining effect keeps the system in the metastable failure state even after the trigger is removed.<BR>This phenomenon of metastable failure is not new. How- ever, instances of such failures look so dissimilar that it is hard to spot the commonality. As a result, distributed systems practitioners have given different names to different instances of metastable failures, such as persistent congestion [51], over- load [60], cascading failures [5], retry storms [2, 56], death spirals [37], among others. Bronson et al. [7] is the first work that generalizes all of these different-looking failures under the same framework.<BR>A key property of metastable failures is that their root cause is not a specific hardware failure or a software bug. It is an emergent behavior of a system, and it naturally arises from the optimizations for the common case that lead to sustained work amplification. As such, metastable failures are hard to predict, may potentially have catastrophic effects, and incur significant ongoing human engineering costs because auto- mated recovery is difficult (since these failures are not under- stood well). For example, in Section 6.3, we discuss how code and configuration changes without truly understanding the metastable failure can exacerbate the problem and lead to fu- ture incidents. Incidentally, at the time of writing this paper, a metastable failure at Amazon Web Services (AWS) disrupted the operation of airlines [38], home appliances [30], smart homes, payment systems [52], and other critical services for several hours.<BR>As Bronson et al. point out, operators choose to run their systems in the vulnerable state all the time because it is much more efficient than running them in the stable state. As a simple example, an operator of a system with a database that can handle 300 requests per second (RPS) can install a cache with a 90% hit-rate and start serving up to 3,000 RPS. While more efficient, the system is now operating in a vulnerable state because a cache failure can overwhelm the database with more requests that it can handle. The problem is that in a complex, large-scale distributed system, we lack the ability to analyze the consequences of this decision to run in a vul- nerable state under different conditions; e.g., what happens if load increases, or if the downstream latency increases, or if messages increase in size and serialization/deserialization starts to cost more CPU? So picking &#8220;how vulnerable&#8221; of a state to operate in, under normal conditions, is a best guess and not always the right choice, which is why we continue to experience metastable failures.