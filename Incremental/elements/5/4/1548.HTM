&nbsp;&nbsp;&nbsp; 1 INTRODUCTION<BR>AXOS [1] provides a formally-proven solution to the fault- tolerant distributed consensus problem. Notably, Paxos never violates the safety specification of distributed consensus (i.e., no two nodes decide differently), even in the case of fully asyn- chronous execution, crash/recovery of the nodes, and arbitrary loss of messages. When the conditions improve such that distributed consensus becomes solvable [2], [3], Paxos also satisfies the progress property (i.e., nodes decide on a value as a function of the inputs). Paxos and its variants have been deployed widely, in- cluding in Chubby [4] based on Paxos [5], Apache ZooKeeper [6] based on Zab [7], and etcd [8] based on Raft [9]. These Paxos implementations depend on a centralized primary process (i.e., the leader) to serialize all commands. Due to this dependence on a single centralized leader, these Paxos implementations support deployments in local area and cannot deal with write-intensive scenarios across wide-area networks (WANs) well. In recent years, however, coordination over wide-area networks (e.g., across zones, such as datacenters and sites) has gained greater importance, especially for database applications and NewSQL datastores [10], [11], [12], distributed filesystems [13], [14], [15], and social<BR>networks [16], [17].<BR>In order to eliminate the single leader bottleneck in Paxos, leaderless and multileader solutions were proposed. EPaxos [18] is a leaderless extension of the Paxos protocol where any replica at any zone can propose and commit commands opportunistically, provided that the commands are non-interfering. This opportunis- tic commit protocol requires an agreement from a fast-quorum of roughly 3/4th of the acceptors1, which means that WAN latencies are still incurred. Moreover, if the commands proposed by multiple concurrent opportunistic proposers do interfere, the protocol requires performing a second phase to record the ac- quired dependencies, and agreement from a majority of the Paxos acceptors is needed. Another way to eliminate the single leader<BR>&nbsp;&nbsp;&nbsp; 1. For a deployment of size 2F + 1, fast-quorum is F + [ F +1 &#9833;</P>
<P><BR>bottleneck is to use a separate Paxos group deployed at each zone. Systems like Google Spanner [10], ZooNet [19], and Bizur [20] achieve this via a static partitioning of the global object-space to different zones, each responsible for a shard of the object-space. However, such static partitioning is inflexible and WAN latencies will be incurred persistently to access/update an object mapped to a different zone.<BR>Contributions. We present WPaxos, a novel multileader Paxos protocol that provides low-latency and high-throughput consensus across WAN deployments. WPaxos leverages the flexible quo- rums [21] idea to cut WAN communication costs. It deploys flexible quorums in a novel manner to appoint multiple concur- rent leaders across the WAN. Unlike the FPaxos protocol [21] which uses a single-leader and does not scale to WAN distances, WPaxos uses multileaders and partitions the object-space among these multileaders. This allows the protocol to process requests for objects under different leaders concurrently. Each object in the system is maintained in its own commit log, allowing for per-object linearizability. By strategically selecting the phase-2 acceptors to be close to the leader, WPaxos achieves fast commit decisions. On the other hand, WPaxos differs from the existing static partitioned multiple Paxos deployment solutions because it implements a dynamic partitioning scheme: leaders coinciding in different zones steal ownership/leadership of an object from each other using phase-1 of Paxos, and then use phase-2 to commit update-requests on the object locally until the object is stolen by another leader.<BR>With its multileader protocol, WPaxos guarantees lineariz- ability per object. We model WPaxos in TLA+/PlusCal [22] and present the algorithm using the PlusCal specification in Section 4. The consistency properties of WPaxos are verified by model checking this specification2.</P>
<P>&nbsp;&nbsp;&nbsp; 2. The TLA+ specification of WPaxos is available at <A href="http://github.com/">http://github.com/</A> ailidani/paxi/tree/master/tla