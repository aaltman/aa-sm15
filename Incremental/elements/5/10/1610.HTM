<b> : </b><A aria-label=Anchor class="anchorjs-link text-decoration-none" style="BOX-SIZING: border-box; FONT-SIZE: 1em; TEXT-DECORATION: none !important; FONT-FAMILY: anchorjs-icons; FONT-VARIANT: normal; POSITION: absolute; FONT-WEIGHT: normal; COLOR: ; FONT-STYLE: normal; PADDING-LEFT: 0.25em; MARGIN-LEFT: -1.25em; PADDING-RIGHT: 0.25em; opacity: 0; -webkit-font-smoothing: antialiased; font-size-adjust: none; font-kerning: auto; font-optical-sizing: auto; font-feature-settings: normal; font-variation-settings: normal; font-stretch: normal" href="https://qdrant.tech/articles/what-is-rag-in-ai/#dense-vector-embeddings" data-anchorjs-icon="&#59851;"></A>Dense vector embeddings</H5>
<P style='BOX-SIZING: border-box; FONT-FAMILY: Satoshi, "Helvetica Neue", "Noto Sans", "Liberation Sans", Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji"; WHITE-SPACE: normal; WORD-SPACING: 0px; MARGIN-TOP: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(40,50,77); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(240,243,250); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial'>This approach uses large language models like<SPAN>&nbsp;</SPAN><A style="BOX-SIZING: border-box; TEXT-DECORATION: none; COLOR: " href="https://en.wikipedia.org/wiki/BERT_(language_model)">BERT</A><SPAN>&nbsp;</SPAN>to encode the query and passages into dense vector embeddings. These models are compact numerical representations that capture semantic meaning. Vector databases like Qdrant store these embeddings, allowing retrieval based on<SPAN>&nbsp;</SPAN><STRONG style="BOX-SIZING: border-box; FONT-WEIGHT: bolder">semantic similarity</STRONG><SPAN>&nbsp;</SPAN>rather than just keywords using distance metrics like cosine similarity.</P>
<P style='BOX-SIZING: border-box; FONT-FAMILY: Satoshi, "Helvetica Neue", "Noto Sans", "Liberation Sans", Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji"; WHITE-SPACE: normal; WORD-SPACING: 0px; MARGIN-TOP: 0px; TEXT-TRANSFORM: none; FONT-WEIGHT: 400; COLOR: rgb(40,50,77); FONT-STYLE: normal; ORPHANS: 2; WIDOWS: 2; LETTER-SPACING: normal; BACKGROUND-COLOR: rgb(240,243,250); TEXT-INDENT: 0px; font-variant-ligatures: normal; font-variant-caps: normal; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial'>This allows the retriever to match based on semantic understanding rather than just keywords. So if I ask about &#8220;compounds that cause BO,&#8221; it can retrieve relevant info about &#8220;molecules that create body odor&#8221; even if those exact words weren&#8217;t used. We explain more about it in our<SPAN>&nbsp;</SPAN><A style="BOX-SIZING: border-box; TEXT-DECORATION: none; COLOR: " href="https://qdrant.tech/articles/what-are-embeddings/">What are Vector Embeddings</A><SPAN>&nbsp;</SPAN>article.