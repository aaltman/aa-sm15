Abstract&#8212;This paper addresses the urgent need to transition to global net-zero carbon emissions by 2050 while retaining the ability to meet joint performance and resilience objectives. The focus is on the computing infrastructures, such as hyper- scale cloud datacenters, that consume significant power, thus producing increasing amounts of carbon emissions. Our goal is to (1) optimize the usage of green energy sources (e.g., solar energy), which is desirable but expensive and relatively unstable, and (2) continuously reduce the use of fossil fuels, which have a lower cost but a significant negative societal impact. Meanwhile, cloud datacenters strive to meet their customers&#8217; requirements, e.g., service-level objectives (SLOs) in application latency or throughput, which are impacted by infrastructure resilience and availability. We propose a scalable formulation that combines sustainability, cloud resilience, and performance as a joint optimization problem with multiple interdependent objectives to address these issues holistically. Given the complexity and dynamicity of the problem, machine learning (ML) approaches, such as reinforcement learning, are essential for achieving continuous optimization. Our study highlights the challenges of green energy instability which necessitates innovative ML- centric solutions across heterogeneous infrastructures to manage the transition towards green computing. Underlying the ML- centric solutions must be methods to combine classic system resilience techniques with innovations in real-time ML resilience (not addressed heretofore). We believe that this approach will not only set a new direction in the resilient, SLO-driven adoption of green energy but also enable us to manage future sustainable systems in ways that were not possible before.<BR>Index Terms&#8212;sustainability, green energy, cloud computing, resilience, machine learning, machine learning resilience<BR>&nbsp;&nbsp;&nbsp; I. INTRODUCTION<BR>Motivation. It has been reported that cloud datacenters&#8217; car- bon emissions already contribute 2&#8211;3% of the overall global carbon footprint, and it has been estimated that they will account for 8% by 2030 [9]. Meanwhile, constantly evolving computing paradigms (e.g., microservices [17], [34], serverless computing [6], [16], and machine learning (ML) [8], [42]) are demanding increasing amounts of power. The energy issues are being further exacerbated by challenges in security and reliability (e.g., Spectre defenses [10]). Given that the underlying hardware technologies have reached a plateau as they approach the limits of their ability to scale with respect to performance and power usage effectiveness, achieving carbon efficiency for a sustainable future is a daunting challenge.<BR>Challenges. As the use of green energy becomes more perva- sive [2], [4], [18], increasing the adoption of green energy in cloud datacenters can scale down the carbon footprint. How-<BR>ever, to achieve that, dependable delivery of customer-specific cloud operations (especially for critical societal applications, such as hospitals and transportation infrastructures) must be an integral part of future sustainable computing. The major challenges to achieving that goal are outlined below:<BR>&nbsp;&nbsp;&nbsp; &#8226; [C1] Fundamental Trade-off between Sustainability and Cloud SLOs. Cloud datacenter operations have service-level objectives (SLOs) that detail performance and resilience requirements [15] regarding latency, throughput, and avail- ability. Sustainable computing requires both sustainable energy costs (by minimizing the carbon footprint) and sus- tainable cloud operations (by meeting SLOs). Conversely, meeting stringent SLOs can incur high energy costs (e.g., due to overprovisioning). Cloud datacenters require careful design and optimization in dealing with this trade-off.<BR>&nbsp;&nbsp;&nbsp; &#8226; [C2] Disruption in Energy Optimization Due to Resilience Management. Failure mitigation and service recovery pro- tocols in cloud datacenters are developed to handle various hardware and software failures (e.g., network link failures and power outages) [19], [31], [32]. However, classic sys- tem resilience introduces disruptions to power optimization by incurring additional energy consumption (due to redun- dancy, migration, and checkpointing). In addition, as ML inference engines are increasingly integrated with today&#8217;s cloud datacenters [7], classic system resilience does not take into account the impact of errors of ML inference, out-of-distribution situations, and data/model uncertainties. Co-designing power and resilience management is required to provide fast failure recovery and differential treatment to critical/non-critical services to minimize disruptions while optimizing carbon footprint.<BR>&nbsp;&nbsp;&nbsp; &#8226; [C3] Variability in Green Energy Supply and Dynamic Workload. Green energy sources are inherently unsta- ble [18], and cloud datacenter workloads also exhibit dy- namically varying spatial and temporal patterns. Combined with [C1], this requires a continuously optimized trade- off between cloud SLO violations and carbon emissions, posing a challenging multi-objective optimization problem.<BR>&nbsp;&nbsp;&nbsp; &#8226; [C4] Lack of an Application-aware Power Control Plane. Substantial efforts have been made towards adopting a top- down approach in maximizing green energy usage, such as workload shifting either spatially or temporally based on predictions of carbon intensity [39]. However, conservative power control misses energy-saving opportunities, while