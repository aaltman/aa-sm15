<b> : </b><SPAN class=section-number style="BOX-SIZING: border-box">3.2.3.<SPAN>&nbsp;</SPAN></SPAN>Device Memory L2 Access Management<A title="Permalink to this headline" class=headerlink style="BOX-SIZING: border-box; CURSOR: pointer; TEXT-DECORATION: none; COLOR: ; FONT: 14px/1 FontAwesome; MARGIN-LEFT: 0.5em; DISPLAY: inline-block; text-rendering: auto; -webkit-font-smoothing: antialiased; opacity: 0" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-l2-access-management">&#61633;</A></H3>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">When a CUDA kernel accesses a data region in the global memory repeatedly, such data accesses can be considered to be<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">persisting</EM>. On the other hand, if the data is only accessed once, such data accesses can be considered to be<SPAN>&nbsp;</SPAN><EM style="BOX-SIZING: border-box">streaming</EM>.</P>
<P style="BOX-SIZING: border-box; COLOR: ; MARGIN: 15px 5px 15px 0px">Starting with CUDA 11.0, devices of compute capability 8.0 and above have the capability to influence persistence of data in the L2 cache, potentially providing higher bandwidth and lower latency accesses to global memory.</P><SECTION id=l2-cache-set-aside-for-persisting-accesses style="BOX-SIZING: border-box; DISPLAY: block"><SPAN id=l2-set-aside style="BOX-SIZING: border-box"></SPAN>